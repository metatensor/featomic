{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Computing density correlations\n\n.. start-body\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ase.io\nimport metatensor as mts\nimport numpy as np\n\nfrom featomic import SphericalExpansion\nfrom featomic.clebsch_gordan import DensityCorrelations, EquivariantPowerSpectrum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing the spherical expansion\n\nWe can define the spherical expansion hyper parameters and compute the density.\nThis will be used throughout the remainder of the tutorial.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "HYPER_PARAMETERS = {\n    \"cutoff\": {\n        \"radius\": 5.0,\n        \"smoothing\": {\"type\": \"ShiftedCosine\", \"width\": 0.5},\n    },\n    \"density\": {\n        \"type\": \"Gaussian\",\n        \"width\": 0.3,\n    },\n    \"basis\": {\n        \"type\": \"TensorProduct\",\n        \"max_angular\": 3,\n        \"radial\": {\"type\": \"Gto\", \"max_radial\": 4},\n    },\n}\n\nsystems = ase.io.read(\"dataset.xyz\", \":\")\n\n# Initialize the SphericalExpansion calculator and compute the density\nspherical_expansion = SphericalExpansion(**HYPER_PARAMETERS)\ndensity = spherical_expansion.compute(systems)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Move to \"neighbor_type\" to properties, i.e. remove sparsity in this dimension.\n\nNote: this method should be called with care when computing on a subset of systems\nfrom a larger dataset. If the ``systems`` being computed contain a subset of the\nglobal atom types, an inconsistent feature dimension will be created. In this case,\nthe argument to ``keys_to_properties`` should be specified as a ``Labels`` object with\nall global atom types.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "density = density.keys_to_properties(\"neighbor_type\")\n\n# average number of features per block\nprint(\"total number of features:\", np.sum([len(block.properties) for block in density]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Density correlations to build a $\\lambda$-SOAP\n\nWe can now use the ``DensityCorrelations`` calculator and specify that we want to take\na single Clebsch-Gordan (CG) tensor product, i.e. ``n_correlations=1``.\n\nDuring initialization, the calculator computes and stores the CG coefficients. As the\ndensity expansion is up to ``o3_lambda=3`` and we are doing a single contraction, we\nneed CG coefficients computed up to ``o3_lambda=6`` in order to do a full contraction.\nHence, we set ``max_angular=6``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "density_correlations = DensityCorrelations(\n    n_correlations=1,\n    max_angular=6,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This outputs an equivariant power spectrum descriptor of body-order 3, i.e.\n$\\lambda$-SOAP features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lambda_soap = density_correlations.compute(density)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is not quite equivalent to the result seen in the previous tutorial on\n`computing \u03bb-SOAP <compute-lambda-soap>`. The keys contain\ndimensions ``\"l_1\"`` and ``\"l_2\"`` which for a given block track the angular order of\nthe blocks from the input combined to create the block in the output\n:class:`~metatensor.TensorMap`.\n\nKeeping these dimensions in the keys is useful to allow for further CG products to be\ntaken, building more complex descriptors. For now, we can move these key dimensions to\nproperties. Inspect the metadata before and after moving these dimensions.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\u03bb-SOAP before keys_to_properties:\", lambda_soap.keys)\nprint(\"first block:\", lambda_soap[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lambda_soap = lambda_soap.keys_to_properties([\"l_1\", \"l_2\"])\n\nprint(\"\u03bb-SOAP after keys_to_properties:\", lambda_soap.keys)\nprint(\"first block:\", lambda_soap[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This obtains a result that is equivalent to the $\\lambda$-SOAP seen in the\nprevious tutorial. We can confirm this by computing an ``EquivariantPowerSpectrum``\nand checking for consistency.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "equivariant_ps_calculator = EquivariantPowerSpectrum(spherical_expansion)\nequivariant_ps = equivariant_ps_calculator.compute(\n    systems, neighbors_to_properties=True\n)\n\nassert mts.equal(lambda_soap, equivariant_ps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Computing the bispectrum\n\nHigher body order descriptors can be computed by increasing the ``n_correlations``\nparameter. The ``max_angular`` should also be increased to account for the increased\ncombinations in angular momenta.\n\nWith more iterations, the cost of the computation scales unfavourably. Let's use a\ndensity with small hyper parameters to demonstrate calculation of the bispectrum, a\nbody-order 4 equivariant descriptor.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "HYPER_PARAMETERS_SMALL = {\n    \"cutoff\": {\n        \"radius\": 5.0,\n        \"smoothing\": {\"type\": \"ShiftedCosine\", \"width\": 0.5},\n    },\n    \"density\": {\n        \"type\": \"Gaussian\",\n        \"width\": 0.3,\n    },\n    \"basis\": {\n        \"type\": \"TensorProduct\",\n        \"max_angular\": 2,\n        \"radial\": {\"type\": \"Gto\", \"max_radial\": 2},\n    },\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Taking two CG combinations of a density expanded to ``o3_lambda=2`` requires CG\ncoefficients computed up to ``max_angular=6``. This is given by ``(n_iterations + 1) *\nmax_angular_density``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initialize the SphericalExpansion calculator and compute the density\nspherical_expansion = SphericalExpansion(**HYPER_PARAMETERS_SMALL)\ndensity = spherical_expansion.compute(systems)\ndensity = density.keys_to_properties(\"neighbor_type\")\n\n# Initialize DensityCorrelations calculator\ndensity_correlations = DensityCorrelations(\n    n_correlations=2,\n    max_angular=6,\n)\n\n# Compute the bispectrum\nbispectrum = density_correlations.compute(density)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are now ``\"neighbor_x_type\"`` and ``\"n_x\"`` (which track the radial channel\nindices) dimensions created by the product of feature spaces of the 3 density blocks\ncombined to make each bispectrum block.\n\nFor each block, its key contains dimensions tracking the angular order of blocks\ncombined to create it, namely ``[\"l_1\", \"l_2\", \"k_2\", \"l_3\"]``. The ``\"l_\"``\ndimensions track the angular order of the blocks from the original density, while\n``\"k_\"`` dimensions track the angular order of intermediate blocks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"bispectrum first block:\", bispectrum[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at an example. Take the block at index 156:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(bispectrum.keys[156])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This was created in the following way.\n\nFirst, a block from ``density`` of angular order ``l_1=1`` was combined with a block\nof order ``l_2=2``. Angular momenta coupling rules state that non-zero combinations\ncan only be created for output blocks with order ``| l_1 - l_2 | <= k_2 <= | l_1 + l_2\n|``, corresponding to ``[1, 2, 3]``. In this case, a block of order ``k_2=1`` was\ncreated.\n\nNext, this intermediate block of order ``k_2=1`` was then combined with a block from\nthe original density of order ``l_3=2``. This can again create combinations ``[1, 2,\n3]``, and in this case has been combined to create the output angular order\n``o3_lambda=3``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As before, we can move these symmetry keys to properties and inspect the metadata and\nthe total size of the features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bispectrum = bispectrum.keys_to_properties([\"l_1\", \"l_2\", \"k_2\", \"l_3\"])\n\nprint(\"first block:\", bispectrum[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    \"total number of features:\",\n    np.sum([len(block.properties) for block in bispectrum]),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of computing the full CG product, a threshold can be defined to limit the\nmaximum angular order of blocks computed at each step in the iterative CG coupling\nsteps.\n\nThis is controlled by the ``angular_cutoff`` parameter, and allows us to initialize\nthe calculator with a lower ``max_angular``.\n\nNote that any truncation of the angular channels away from the maximal allowed by\nangular momenta coupling rules results in some loss of information.\n\nLet's truncate to an angular cutoff of 3:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "angular_cutoff = 3\ndensity_correlations = DensityCorrelations(\n    n_correlations=2,\n    max_angular=angular_cutoff,\n)\nbispectrum_truncated = density_correlations.compute(\n    density, angular_cutoff=angular_cutoff\n)\n\n# Move the \"l_\" and \"k_\" keys to properties\nbispectrum_truncated = bispectrum_truncated.keys_to_properties(\n    [\"l_1\", \"l_2\", \"k_2\", \"l_3\"]\n)\n\nprint(\"truncated bispectrum:\", bispectrum_truncated.keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"first block:\", bispectrum_truncated[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    \"total number of features:\",\n    np.sum([len(block.properties) for block in bispectrum_truncated]),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To compute a descriptor that matches the symmetry of a given target property, the\n``selected_keys`` argument can be passed to the ``compute`` method. This was also seen\nin the previous tutorial on `computing lambda-SOAP <compute-lambda-soap>`.\n\nFollowing this example, to compute the truncated bispectrum for a polarizability\ntensor:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bispectrum_truncated_key_select = density_correlations.compute(\n    density,\n    angular_cutoff=angular_cutoff,\n    selected_keys=mts.Labels(\n        [\"o3_lambda\", \"o3_sigma\"],\n        np.array([[0, 1], [2, 1]]),\n    ),\n)\n\n# Move the \"l_\" and \"k_\" keys to properties\nbispectrum_truncated_key_select = bispectrum_truncated_key_select.keys_to_properties(\n    [\"l_1\", \"l_2\", \"k_2\", \"l_3\"]\n)\n\nprint(\"truncated bispectrum with selected keys:\", bispectrum_truncated_key_select.keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\n    \"total number of features:\",\n    np.sum([len(block.properties) for block in bispectrum_truncated_key_select]),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n\n``DensityCorrelations`` can be used to build equivariants of arbitrary body order from\na spherical expansion of decorated atomic point cloud data.\n\nA key limitation of this approach is an exploding feature size. To reduce the number\nof output blocks, the ``angular_cutoff`` parameter can be used.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. end-body\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}